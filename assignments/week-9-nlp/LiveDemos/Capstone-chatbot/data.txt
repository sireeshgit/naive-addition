The main concern for Logistics companies like Amazon that ship millions of packages daily often waste space when they pack items into bins, containers, and trucks. There is a large opportunity to decrease shipping costs by increasing packing effectiveness with the appropriate machine learning algorithm.3D packaging research indicates that a 6% volume savings for 15 containers (~3,000 packages) can reduce costs by at least $7,000.  This is a research-focused project focused on reinforcement learning. Successful projects will design and implement an environment that trains a reinforcement learning agent associated with a real-world use case using object-oriented Python. The key performance indicator for 3d packaging must be developed based on a set of open-ended research questions (see “What” section). For a company like Amazon that ships 1.6M packages daily, a cost reduction of $3.7M ($7,000*1.6M/3,000) per day is theoretically possible.  Design and implement an environment with object-oriented Python to train a reinforcement learning agent to pack boxes most optimally in a container.



GLG powers great decisions through their network of experts. GLG company receives hundreds of daily requests from clients seeking insights on topics ranging from the airline industry’s ability to cope with COVID-19 to the zebra mussel infestations in North America. The goal of GLG is to match each request to a topic specialist in their database. This project on Natural Language Processing (NLP) is aimed at improving the topic/keyword detection process from the client submitted reports and identifying the underlying patterns in submitted requests over time. The primary challenges include Named Entity Recognition (NER) and Pattern Recognition for Hierarchical Clustering of Topics. Typically for GLG, the client requests include a form with unstructured free text with screening questions. Thus, we need to group these requests into common topics – to better understand service demand. This project is aimed to increase the resourcefulness of the current data pipelines for efficient data storage and retrieval. Match Free text requests with the most relevant Topic Specialist. Create a hierarchical dendrogram of the topics requested over time.


MovieBot creates a dynamic and usable chatbot that will collect user interests and preferences, then that chatbot will recommend a movie based on the related content.

Data annotation, specifically for image data sets, is a challenging task since it requires a rigorous manual training process that is time and cost-intensive to ensure standardized outcomes. The global data collection and labeling market was estimated as a 1.3B$ market in 2020 with a compound growth rate of 25.6% from 2021 to 2026. This necessitates using Deep Learning/Machine Learning algorithms to standardize the annotation process and make it more cost-efficient. Recent works on automated semantic segmentation platforms such as Curve-GCN (Source: https://arxiv.org/pdf/1903.06874.pdf) demonstrate that once a region of interest is manually selected by a user, there are automated algorithms that can detect the exact boundaries of objects as shown here. This is just an example annotation frontend. This process significantly reduces the annotation time to separate exact object boundaries. In this project, we streamline the manual annotation process by combining the Curve GCN or SIMILAR METHODS with automated bounding box detection algorithms (such as YOLOv3 or alike). The intention is to automate the semantic segmentation process as much as possible to minimize manual labeling effort. The overall system can then be tested on public data sets of outdoor and indoor images.

Drug development and discovery is a time and labor-intensive process that has the potential to be enhanced and improved by next-generation protein sequencing techniques. Recent breakthroughs in Natural Language Processing (NLP) and training of large transformer models have paved the way for new domain-specific deep language models.  In the biological domain, the development of general-purpose protein language models that are capable of predicting specific protein types could, among other things, pave the way to more effective, safer cancer treatments.


Decreased time in range (TIR) of healthy glucose levels is associated with negative health outcomes. The project seeks to develop a machine learning model to predict high glycemic risk patients (e.g., future decreases in TIR) so that they may be identified for follow-up and intervention by a healthcare provider. This problem is worth solving because decreased TIR is associated with worsening health outcomes and increased healthcare costs. Healthcare providers (e.g., doctors) are seeking ways to improve the quality and cost-efficiency of diabetes care. Accurate prediction of high-risk patients allows for intervention that may prevent future hospital visits and associated complications.